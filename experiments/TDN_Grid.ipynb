{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "NEG_INF = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Env:\n",
    "    index_to_direction = [\n",
    "        [ 0,-1],\n",
    "        [ 0, 1],\n",
    "        [-1, 0],\n",
    "        [ 1, 0]]\n",
    "    \n",
    "    def __init__(self, n = 5,start_x = 3,start_y = 3,end_states = {(0,0)},random_start = False):\n",
    "        self.start_x = start_x\n",
    "        self.start_y = start_y\n",
    "        self.x = self.start_x\n",
    "        self.y = self.start_y\n",
    "        self.n = n\n",
    "        self.end_states = end_states\n",
    "        self.random_start = random_start\n",
    "        \n",
    "    def get_next_state(self,action):\n",
    "        tx = self.x + self.index_to_direction[action][0]\n",
    "        ty = self.y + self.index_to_direction[action][1]\n",
    "            \n",
    "        return (tx,ty)\n",
    "    \n",
    "    def is_valid(self,x,y):\n",
    "        if x < 0 or x >= self.n or y < 0 or y >= self.n:\n",
    "            return False\n",
    "        return True\n",
    "        \n",
    "    def reset(self):\n",
    "        if self.random_start:\n",
    "            self.x = random.randint(0,self.n-1)\n",
    "            self.y = random.randint(0,self.n-1)\n",
    "        else:\n",
    "            self.x = self.start_x\n",
    "            self.y = self.start_y\n",
    "        return (self.x,self.y)\n",
    "    \n",
    "    def get_all_actions(self):\n",
    "        return [i for i in range(len(self.index_to_direction))]\n",
    "    \n",
    "    def get_actions(self):\n",
    "        actions = []\n",
    "        for i in range(len(self.index_to_direction)):\n",
    "            if self.is_valid(self.x + self.index_to_direction[i][0],self.y + self.index_to_direction[i][1]):\n",
    "                actions.append(i)\n",
    "        return actions\n",
    "    \n",
    "    \n",
    "    def get_actions_at_state(self,state):\n",
    "        actions = []\n",
    "        for i in range(len(self.index_to_direction)):\n",
    "            if self.is_valid(state[0] + self.index_to_direction[i][0],state[1] + self.index_to_direction[i][1]):\n",
    "                actions.append(i)\n",
    "        return actions\n",
    "    \n",
    "    def get_random_action_at_state(self,state):\n",
    "        return random.choice(self.get_actions_at_state(state))\n",
    "    \n",
    "    def get_random_action(self):\n",
    "        return random.choice(self.get_actions())\n",
    "    \n",
    "    def step(self,action):\n",
    "        self.x = self.x + self.index_to_direction[action][0]\n",
    "        self.y = self.y + self.index_to_direction[action][1]\n",
    "        \n",
    "        reward = -1\n",
    "        done = False\n",
    "        if (self.x,self.y) in self.end_states:\n",
    "            reward = 0\n",
    "            done = True\n",
    "            \n",
    "        return (self.x,self.y),reward,done,None\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def print_state_action():\n",
    "    g = []\n",
    "    for i in range(env.n):\n",
    "        t = []\n",
    "        for j in range(env.n):\n",
    "            t.append(-9999.0)\n",
    "        g.append(t)\n",
    "\n",
    "        \n",
    "    \n",
    "    for i in range(env.n):\n",
    "        for j in range(env.n):\n",
    "            for action in env.get_all_actions():\n",
    "                sa = ((i,j),action)\n",
    "                if (sa) in state_action:\n",
    "                    g[i][j] = max(g[i][j],state_action[sa])\n",
    "    \n",
    "    \n",
    "    for i in range(env.n):\n",
    "        for j in range(env.n):\n",
    "            if(g[i][j] == -9999.0):\n",
    "                g[i][j] = 0\n",
    "    \n",
    "    \n",
    "    \n",
    "    for i in range(env.n):\n",
    "        for j in range(env.n):\n",
    "            print(\"%-3.2f \"%(g[i][j]),end=\"\")\n",
    "        print()\n",
    "\n",
    "\n",
    "        \n",
    "def print_heat_map():\n",
    "    g = []\n",
    "    for i in range(env.n):\n",
    "        t = []\n",
    "        for j in range(env.n):\n",
    "            t.append(-9999.0)\n",
    "        g.append(t)\n",
    "\n",
    "        \n",
    "    \n",
    "    for i in range(env.n):\n",
    "        for j in range(env.n):\n",
    "            for action in env.get_all_actions():\n",
    "                sa = ((i,j),action)\n",
    "                if (sa) in state_action:\n",
    "                    g[i][j] = max(g[i][j],state_action[sa])\n",
    "    \n",
    "    \n",
    "    for i in range(env.n):\n",
    "        for j in range(env.n):\n",
    "            if(g[i][j] == -9999.0):\n",
    "                g[i][j] = 0\n",
    "    \n",
    "#     for i in range(env.n):\n",
    "#         for j in range(env.n):\n",
    "#             print(\"%-3.2f \"%(g[i][j]),end=\"\")\n",
    "#         print()\n",
    "\n",
    "    \n",
    "    a = np.array(g)\n",
    "    plt.imshow(a, cmap='hot', interpolation='nearest')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def set_state_action(sa):\n",
    "    global state_action\n",
    "    if sa not in state_action:\n",
    "        state_action[sa] = NEG_INF\n",
    "\n",
    "def get_action(obs):\n",
    "    global env\n",
    "    \n",
    "    t = random.random()\n",
    "    if t < exploration:\n",
    "        return env.get_random_action_at_state(obs)\n",
    "    else:\n",
    "        act = env.get_random_action_at_state(obs)\n",
    "        val = NEG_INF\n",
    "        for action in env.get_actions_at_state(obs): \n",
    "            sa = (obs,action)\n",
    "            set_state_action(sa)\n",
    "            if state_action[sa] > val:\n",
    "                act = action\n",
    "                val = state_action[sa]\n",
    "            \n",
    "        return act\n",
    "\n",
    "## This is SARSA\n",
    "def update_state_action(n,states,actions,rewards):\n",
    "    current_sa = (states[0],actions[0])\n",
    "    set_state_action(current_sa)\n",
    "    \n",
    "    total_rewards = 0\n",
    "    for i in range(len(rewards)):\n",
    "        total_rewards += pow(discount_rate,i+1) * rewards[i]\n",
    "    \n",
    "    next_action = get_action(states[-1])\n",
    "    next_sa = (states[-1],next_action)  \n",
    "    set_state_action(next_sa)\n",
    "\n",
    "    \n",
    "#     print(states,actions,rewards,state_action[current_sa])\n",
    "#     print(current_sa,total_rewards + pow(discount_rate,n)*state_action[next_sa],state_action[current_sa])\n",
    "    \n",
    "    state_action[current_sa] = state_action[current_sa] + learning_rate*(total_rewards + pow(discount_rate,n)*state_action[next_sa] - state_action[current_sa]) \n",
    "#     print(state_action[current_sa])\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(n,no_episodes = 10,episode_length = 10):\n",
    "    global exploration,env\n",
    "\n",
    "    for ep in range(no_episodes):\n",
    "        states = []\n",
    "        actions = []\n",
    "        rewards = []\n",
    "        \n",
    "        obs = env.reset()\n",
    "        if obs in env.end_states:\n",
    "            continue\n",
    "        \n",
    "        \n",
    "        for i in range(episode_length):\n",
    "            action = get_action(obs)\n",
    "            new_obs, reward, done, _ = env.step(action)\n",
    "            \n",
    "            states.append(obs)\n",
    "            actions.append(action)\n",
    "            rewards.append(reward)\n",
    "            obs = new_obs\n",
    "            if len(states) > n:\n",
    "                states = states[1:]\n",
    "                actions = actions[1:]\n",
    "                rewards = rewards[1:]\n",
    "            \n",
    "            if len(states) < n:\n",
    "                continue\n",
    "            \n",
    "            if done:\n",
    "                break\n",
    "                \n",
    "            update_state_action(n,states,actions,rewards)\n",
    "            \n",
    "            if done:\n",
    "                break\n",
    "#         print(\"#\"*10+\" EP OVER \" + \"#\"*10)\n",
    "        exploration = exploration * 0.999\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "## (state,action) -> reward\n",
    "state_action = {}\n",
    "\n",
    "exploration = 0.7\n",
    "learning_rate = 0.4\n",
    "discount_rate = 1\n",
    "n = 12\n",
    "env = Env(n=15,start_x = 2,start_y = 2,end_states = {(0,0),(4,7)},random_start=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "train(n,2000,30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print_heat_map()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.19408619345261716"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{((2, 2), 0): -9.085623482428739,\n",
       " ((2, 2), 2): -9.55743046505059,\n",
       " ((1, 2), 0): -4.772364,\n",
       " ((1, 2), 2): -7.7879213643308765,\n",
       " ((1, 2), 3): -9.680326548937606,\n",
       " ((1, 1), 0): -5.120625931074919,\n",
       " ((1, 1), 1): -5.0029452,\n",
       " ((1, 1), 2): -3.0274799999999997,\n",
       " ((1, 1), 3): -3.924503371716,\n",
       " ((1, 0), 1): -1.8119999999999998,\n",
       " ((1, 0), 2): 0,\n",
       " ((1, 0), 3): -5.429997841468103,\n",
       " ((2, 0), 1): -4.928974687497361,\n",
       " ((2, 0), 2): -6.82681491388452,\n",
       " ((2, 1), 0): -7.407886936301172,\n",
       " ((2, 1), 1): -9.430888306136618,\n",
       " ((2, 1), 2): -7.7011905240075444,\n",
       " ((0, 1), 0): 0,\n",
       " ((0, 1), 1): 0,\n",
       " ((0, 1), 3): -1.2,\n",
       " ((0, 2), 0): -6.23628618345444,\n",
       " ((0, 2), 3): -4.8503660808903515}"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state_action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
