{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "NEG_INF = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Env:\n",
    "    index_to_direction = [\n",
    "        [ 0,-1],\n",
    "        [ 0, 1],\n",
    "        [-1, 0],\n",
    "        [ 1, 0]]\n",
    "    \n",
    "    def __init__(self, n = 5,start_x = 3,start_y = 3,end_states = {(0,0)},random_start = False):\n",
    "        self.start_x = start_x\n",
    "        self.start_y = start_y\n",
    "        self.x = self.start_x\n",
    "        self.y = self.start_y\n",
    "        self.n = n\n",
    "        self.end_states = end_states\n",
    "        self.random_start = random_start\n",
    "        \n",
    "    def get_next_state(self,action):\n",
    "        tx = self.x + self.index_to_direction[action][0]\n",
    "        ty = self.y + self.index_to_direction[action][1]\n",
    "            \n",
    "        return (tx,ty)\n",
    "    \n",
    "    def is_valid(self,x,y):\n",
    "        if x < 0 or x >= self.n or y < 0 or y >= self.n:\n",
    "            return False\n",
    "        return True\n",
    "        \n",
    "    def reset(self):\n",
    "        if self.random_start:\n",
    "            self.x = random.randint(0,self.n-1)\n",
    "            self.y = random.randint(0,self.n-1)\n",
    "        else:\n",
    "            self.x = self.start_x\n",
    "            self.y = self.start_y\n",
    "        return (self.x,self.y)\n",
    "    \n",
    "    def get_all_actions(self):\n",
    "        return [i for i in range(len(self.index_to_direction))]\n",
    "    \n",
    "    def get_actions(self):\n",
    "        actions = []\n",
    "        for i in range(len(self.index_to_direction)):\n",
    "            if self.is_valid(self.x + self.index_to_direction[i][0],self.y + self.index_to_direction[i][1]):\n",
    "                actions.append(i)\n",
    "        return actions\n",
    "    \n",
    "    \n",
    "    def get_actions_at_state(self,state):\n",
    "        actions = []\n",
    "        for i in range(len(self.index_to_direction)):\n",
    "            if self.is_valid(state[0] + self.index_to_direction[i][0],state[1] + self.index_to_direction[i][1]):\n",
    "                actions.append(i)\n",
    "        return actions\n",
    "    \n",
    "    def get_random_action_at_state(self,state):\n",
    "        return random.choice(self.get_actions_at_state(state))\n",
    "    \n",
    "    def get_random_action(self):\n",
    "        return random.choice(self.get_actions())\n",
    "    \n",
    "    def step(self,action):\n",
    "        self.x = self.x + self.index_to_direction[action][0]\n",
    "        self.y = self.y + self.index_to_direction[action][1]\n",
    "        \n",
    "        reward = -1\n",
    "        done = False\n",
    "        if (self.x,self.y) in self.end_states:\n",
    "            reward = 0\n",
    "            done = True\n",
    "            \n",
    "        return (self.x,self.y),reward,done,None\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def print_state_action():\n",
    "    g = []\n",
    "    for i in range(env.n):\n",
    "        t = []\n",
    "        for j in range(env.n):\n",
    "            t.append(-9999.0)\n",
    "        g.append(t)\n",
    "\n",
    "        \n",
    "    \n",
    "    for i in range(env.n):\n",
    "        for j in range(env.n):\n",
    "            for action in env.get_all_actions():\n",
    "                sa = ((i,j),action)\n",
    "                if (sa) in state_action:\n",
    "                    g[i][j] = max(g[i][j],state_action[sa])\n",
    "    \n",
    "    \n",
    "    for i in range(env.n):\n",
    "        for j in range(env.n):\n",
    "            if(g[i][j] == -9999.0):\n",
    "                g[i][j] = 0\n",
    "    \n",
    "    \n",
    "    \n",
    "    for i in range(env.n):\n",
    "        for j in range(env.n):\n",
    "            print(\"%-3.2f \"%(g[i][j]),end=\"\")\n",
    "        print()\n",
    "\n",
    "\n",
    "        \n",
    "def print_heat_map():\n",
    "    g = []\n",
    "    for i in range(env.n):\n",
    "        t = []\n",
    "        for j in range(env.n):\n",
    "            t.append(-9999.0)\n",
    "        g.append(t)\n",
    "\n",
    "        \n",
    "    \n",
    "    for i in range(env.n):\n",
    "        for j in range(env.n):\n",
    "            for action in env.get_all_actions():\n",
    "                sa = ((i,j),action)\n",
    "                if (sa) in state_action:\n",
    "                    g[i][j] = max(g[i][j],state_action[sa])\n",
    "    \n",
    "    \n",
    "    for i in range(env.n):\n",
    "        for j in range(env.n):\n",
    "            if(g[i][j] == -9999.0):\n",
    "                g[i][j] = 0\n",
    "    \n",
    "#     for i in range(env.n):\n",
    "#         for j in range(env.n):\n",
    "#             print(\"%-3.2f \"%(g[i][j]),end=\"\")\n",
    "#         print()\n",
    "\n",
    "    \n",
    "    a = np.array(g)\n",
    "    plt.imshow(a, cmap='hot', interpolation='nearest')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def set_state_action(sa):\n",
    "    global state_action\n",
    "    if sa not in state_action:\n",
    "        state_action[sa] = NEG_INF\n",
    "\n",
    "def get_action(obs):\n",
    "    global env\n",
    "    \n",
    "    t = random.random()\n",
    "    if t < exploration:\n",
    "        return env.get_random_action_at_state(obs)\n",
    "    else:\n",
    "        act = env.get_random_action_at_state(obs)\n",
    "        val = NEG_INF\n",
    "        for action in env.get_actions_at_state(obs): \n",
    "            sa = (obs,action)\n",
    "            set_state_action(sa)\n",
    "            if state_action[sa] > val:\n",
    "                act = action\n",
    "                val = state_action[sa]\n",
    "            \n",
    "        return act\n",
    "\n",
    "## This is SARSA\n",
    "def update_state_action(n,states,actions,rewards):\n",
    "    current_sa = (states[0],actions[0])\n",
    "    set_state_action(current_sa)\n",
    "    \n",
    "    total_rewards = 0\n",
    "    for i in range(len(rewards)):\n",
    "        total_rewards += pow(discount_rate,i+1) * rewards[i]\n",
    "    \n",
    "    next_action = get_action(states[-1])\n",
    "    next_sa = (states[-1],next_action)  \n",
    "    set_state_action(next_sa)\n",
    "\n",
    "    \n",
    "#     print(states,actions,rewards,state_action[current_sa])\n",
    "#     print(current_sa,total_rewards + pow(discount_rate,n)*state_action[next_sa],state_action[current_sa])\n",
    "    \n",
    "    state_action[current_sa] = state_action[current_sa] + learning_rate*(total_rewards + pow(discount_rate,n)*state_action[next_sa] - state_action[current_sa]) \n",
    "#     print(state_action[current_sa])\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(n,no_episodes = 10,episode_length = 10):\n",
    "    global exploration,env\n",
    "\n",
    "    for ep in range(no_episodes):\n",
    "        states = []\n",
    "        actions = []\n",
    "        rewards = []\n",
    "        \n",
    "        obs = env.reset()\n",
    "        if obs in env.end_states:\n",
    "            continue\n",
    "        \n",
    "        \n",
    "        for i in range(episode_length):\n",
    "            action = get_action(obs)\n",
    "            new_obs, reward, done, _ = env.step(action)\n",
    "            \n",
    "            states.append(obs)\n",
    "            actions.append(action)\n",
    "            rewards.append(reward)\n",
    "            obs = new_obs\n",
    "            if len(states) > n:\n",
    "                states = states[1:]\n",
    "                actions = actions[1:]\n",
    "                rewards = rewards[1:]\n",
    "            \n",
    "            if done:\n",
    "                break\n",
    "                \n",
    "            if len(states) < n:\n",
    "                continue\n",
    "            \n",
    "                \n",
    "            update_state_action(n,states,actions,rewards)\n",
    "            \n",
    "            if done:\n",
    "                break\n",
    "#         print(\"#\"*10+\" EP OVER \" + \"#\"*10)\n",
    "        exploration = exploration * 0.999\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "## (state,action) -> reward\n",
    "state_action = {}\n",
    "\n",
    "exploration = 0.7\n",
    "learning_rate = 0.4\n",
    "discount_rate = 1\n",
    "n = 12\n",
    "env = Env(n=15,start_x = 2,start_y = 2,end_states = {(0,0),(4,7)},random_start=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "train(n,2000,30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print_heat_map()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.19408619345261716"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{((2, 2), 0): -9.085623482428739,\n",
       " ((2, 2), 2): -9.55743046505059,\n",
       " ((1, 2), 0): -4.772364,\n",
       " ((1, 2), 2): -7.7879213643308765,\n",
       " ((1, 2), 3): -9.680326548937606,\n",
       " ((1, 1), 0): -5.120625931074919,\n",
       " ((1, 1), 1): -5.0029452,\n",
       " ((1, 1), 2): -3.0274799999999997,\n",
       " ((1, 1), 3): -3.924503371716,\n",
       " ((1, 0), 1): -1.8119999999999998,\n",
       " ((1, 0), 2): 0,\n",
       " ((1, 0), 3): -5.429997841468103,\n",
       " ((2, 0), 1): -4.928974687497361,\n",
       " ((2, 0), 2): -6.82681491388452,\n",
       " ((2, 1), 0): -7.407886936301172,\n",
       " ((2, 1), 1): -9.430888306136618,\n",
       " ((2, 1), 2): -7.7011905240075444,\n",
       " ((0, 1), 0): 0,\n",
       " ((0, 1), 1): 0,\n",
       " ((0, 1), 3): -1.2,\n",
       " ((0, 2), 0): -6.23628618345444,\n",
       " ((0, 2), 3): -4.8503660808903515}"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state_action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
